{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U torch transformers peft datasets bitsandbytes trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WQ60bZwo7O5P",
        "outputId": "a57f4e80-16bf-4128-bbc0-2c2473fb21aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.4/517.4 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required libraries\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n"
      ],
      "metadata": {
        "id": "TsXCEE5-7TGl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hq_dataset = load_dataset(\"sahil2801/CodeAlpaca-20k\", split=\"train\").select(range(1000))"
      ],
      "metadata": {
        "id": "MQlxqUOz8NU5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lq_dataset = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\", streaming=True).take(5000)\n",
        "def format_hq(sample):\n",
        "    return f\"### Instruction:\\n{sample['instruction']}\\n\\n### Response:\\n{sample['output']}\"\n",
        "\n",
        "# Format for Low Quality (Raw Chaos)\n",
        "def format_lq(sample):\n",
        "    return f\"### Code Snippet:\\n{sample['content']}\"\n",
        "\n",
        "print(f\"Sample HQ Data:\\n{format_hq(hq_dataset[0])}\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"Sample LQ Data:\\n{format_lq(next(iter(lq_dataset)))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P3tNuMK8oNY",
        "outputId": "dc44ddf1-4889-48d4-f5f4-c0b3d468728c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample HQ Data:\n",
            "### Instruction:\n",
            "Create an array of length 5 which contains all even numbers between 1 and 10.\n",
            "\n",
            "### Response:\n",
            "arr = [2, 4, 6, 8, 10]\n",
            "--------------------\n",
            "Sample LQ Data:\n",
            "### Code Snippet:\n",
            "\"\"\"\n",
            "The :mod:`sklearn.utils` module includes various utilites.\n",
            "\"\"\"\n",
            "\n",
            "from collections import Sequence\n",
            "\n",
            "import numpy as np\n",
            "from scipy.sparse import issparse\n",
            "import warnings\n",
            "\n",
            "from .murmurhash import murmurhash3_32\n",
            "from .validation import (as_float_array, check_arrays, safe_asarray,\n",
            "                         assert_all_finite, array2d, atleast2d_or_csc,\n",
            "                         atleast2d_or_csr, warn_if_not_float,\n",
            "                         check_random_state)\n",
            "from .class_weight import compute_class_weight\n",
            "\n",
            "__all__ = [\"murmurhash3_32\", \"as_float_array\", \"check_arrays\", \"safe_asarray\",\n",
            "           \"assert_all_finite\", \"array2d\", \"atleast2d_or_csc\",\n",
            "           \"atleast2d_or_csr\", \"warn_if_not_float\", \"check_random_state\",\n",
            "           \"compute_class_weight\"]\n",
            "\n",
            "# Make sure that DeprecationWarning get printed\n",
            "warnings.simplefilter(\"always\", DeprecationWarning)\n",
            "\n",
            "\n",
            "class deprecated(object):\n",
            "    \"\"\"Decorator to mark a function or class as deprecated.\n",
            "\n",
            "    Issue a warning when the function is called/the class is instantiated and\n",
            "    adds a warning to the docstring.\n",
            "\n",
            "    The optional extra argument will be appended to the deprecation message\n",
            "    and the docstring. Note: to use this with the default value for extra, put\n",
            "    in an empty of parentheses:\n",
            "\n",
            "    >>> from sklearn.utils import deprecated\n",
            "    >>> deprecated() # doctest: +ELLIPSIS\n",
            "    <sklearn.utils.deprecated object at ...>\n",
            "\n",
            "    >>> @deprecated()\n",
            "    ... def some_function(): pass\n",
            "    \"\"\"\n",
            "\n",
            "    # Adapted from http://wiki.python.org/moin/PythonDecoratorLibrary,\n",
            "    # but with many changes.\n",
            "\n",
            "    def __init__(self, extra=''):\n",
            "        \"\"\"\n",
            "        Parameters\n",
            "        ----------\n",
            "        extra: string\n",
            "          to be added to the deprecation messages\n",
            "\n",
            "        \"\"\"\n",
            "        self.extra = extra\n",
            "\n",
            "    def __call__(self, obj):\n",
            "        if isinstance(obj, type):\n",
            "            return self._decorate_class(obj)\n",
            "        else:\n",
            "            return self._decorate_fun(obj)\n",
            "\n",
            "    def _decorate_class(self, cls):\n",
            "        msg = \"Class %s is deprecated\" % cls.__name__\n",
            "        if self.extra:\n",
            "            msg += \"; %s\" % self.extra\n",
            "\n",
            "        # FIXME: we should probably reset __new__ for full generality\n",
            "        init = cls.__init__\n",
            "\n",
            "        def wrapped(*args, **kwargs):\n",
            "            warnings.warn(msg, category=DeprecationWarning)\n",
            "            return init(*args, **kwargs)\n",
            "        cls.__init__ = wrapped\n",
            "\n",
            "        wrapped.__name__ = '__init__'\n",
            "        wrapped.__doc__ = self._update_doc(init.__doc__)\n",
            "        wrapped.deprecated_original = init\n",
            "\n",
            "        return cls\n",
            "\n",
            "    def _decorate_fun(self, fun):\n",
            "        \"\"\"Decorate function fun\"\"\"\n",
            "\n",
            "        msg = \"Function %s is deprecated\" % fun.__name__\n",
            "        if self.extra:\n",
            "            msg += \"; %s\" % self.extra\n",
            "\n",
            "        def wrapped(*args, **kwargs):\n",
            "            warnings.warn(msg, category=DeprecationWarning)\n",
            "            return fun(*args, **kwargs)\n",
            "\n",
            "        wrapped.__name__ = fun.__name__\n",
            "        wrapped.__dict__ = fun.__dict__\n",
            "        wrapped.__doc__ = self._update_doc(fun.__doc__)\n",
            "\n",
            "        return wrapped\n",
            "\n",
            "    def _update_doc(self, olddoc):\n",
            "        newdoc = \"DEPRECATED\"\n",
            "        if self.extra:\n",
            "            newdoc = \"%s: %s\" % (newdoc, self.extra)\n",
            "        if olddoc:\n",
            "            newdoc = \"%s\\n\\n%s\" % (newdoc, olddoc)\n",
            "        return newdoc\n",
            "\n",
            "\n",
            "def safe_mask(X, mask):\n",
            "    \"\"\"Return a mask which is safe to use on X.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    X : {array-like, sparse matrix}\n",
            "        Data on which to apply mask.\n",
            "\n",
            "    mask: array\n",
            "        Mask to be used on X.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "        mask\n",
            "    \"\"\"\n",
            "    mask = np.asanyarray(mask)\n",
            "    if np.issubdtype(mask.dtype, np.int):\n",
            "        return mask\n",
            "\n",
            "    if hasattr(X, \"toarray\"):\n",
            "        ind = np.arange(mask.shape[0])\n",
            "        mask = ind[mask]\n",
            "    return mask\n",
            "\n",
            "\n",
            "def resample(*arrays, **options):\n",
            "    \"\"\"Resample arrays or sparse matrices in a consistent way\n",
            "\n",
            "    The default strategy implements one step of the bootstrapping\n",
            "    procedure.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\n",
            "\n",
            "    replace : boolean, True by default\n",
            "        Implements resampling with replacement. If False, this will implement\n",
            "        (sliced) random permutations.\n",
            "\n",
            "    n_samples : int, None by default\n",
            "        Number of samples to generate. If left to None this is\n",
            "        automatically set to the first dimension of the arrays.\n",
            "\n",
            "    random_state : int or RandomState instance\n",
            "        Control the shuffling for reproducible behavior.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    Sequence of resampled views of the collections. The original arrays are\n",
            "    not impacted.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    It is possible to mix sparse and dense arrays in the same run::\n",
            "\n",
            "      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\n",
            "      >>> y = np.array([0, 1, 2])\n",
            "\n",
            "      >>> from scipy.sparse import coo_matrix\n",
            "      >>> X_sparse = coo_matrix(X)\n",
            "\n",
            "      >>> from sklearn.utils import resample\n",
            "      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n",
            "      >>> X\n",
            "      array([[ 1.,  0.],\n",
            "             [ 2.,  1.],\n",
            "             [ 1.,  0.]])\n",
            "\n",
            "      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
            "      <3x2 sparse matrix of type '<... 'numpy.float64'>'\n",
            "          with 4 stored elements in Compressed Sparse Row format>\n",
            "\n",
            "      >>> X_sparse.toarray()\n",
            "      array([[ 1.,  0.],\n",
            "             [ 2.,  1.],\n",
            "             [ 1.,  0.]])\n",
            "\n",
            "      >>> y\n",
            "      array([0, 1, 0])\n",
            "\n",
            "      >>> resample(y, n_samples=2, random_state=0)\n",
            "      array([0, 1])\n",
            "\n",
            "\n",
            "    See also\n",
            "    --------\n",
            "    :class:`sklearn.cross_validation.Bootstrap`\n",
            "    :func:`sklearn.utils.shuffle`\n",
            "    \"\"\"\n",
            "    random_state = check_random_state(options.pop('random_state', None))\n",
            "    replace = options.pop('replace', True)\n",
            "    max_n_samples = options.pop('n_samples', None)\n",
            "    if options:\n",
            "        raise ValueError(\"Unexpected kw arguments: %r\" % options.keys())\n",
            "\n",
            "    if len(arrays) == 0:\n",
            "        return None\n",
            "\n",
            "    first = arrays[0]\n",
            "    n_samples = first.shape[0] if hasattr(first, 'shape') else len(first)\n",
            "\n",
            "    if max_n_samples is None:\n",
            "        max_n_samples = n_samples\n",
            "\n",
            "    if max_n_samples > n_samples:\n",
            "        raise ValueError(\"Cannot sample %d out of arrays with dim %d\" % (\n",
            "            max_n_samples, n_samples))\n",
            "\n",
            "    arrays = check_arrays(*arrays, sparse_format='csr')\n",
            "\n",
            "    if replace:\n",
            "        indices = random_state.randint(0, n_samples, size=(max_n_samples,))\n",
            "    else:\n",
            "        indices = np.arange(n_samples)\n",
            "        random_state.shuffle(indices)\n",
            "        indices = indices[:max_n_samples]\n",
            "\n",
            "    resampled_arrays = []\n",
            "\n",
            "    for array in arrays:\n",
            "        array = array[indices]\n",
            "        resampled_arrays.append(array)\n",
            "\n",
            "    if len(resampled_arrays) == 1:\n",
            "        # syntactic sugar for the unit argument case\n",
            "        return resampled_arrays[0]\n",
            "    else:\n",
            "        return resampled_arrays\n",
            "\n",
            "\n",
            "def shuffle(*arrays, **options):\n",
            "    \"\"\"Shuffle arrays or sparse matrices in a consistent way\n",
            "\n",
            "    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\n",
            "    random permutations of the collections.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\n",
            "\n",
            "    random_state : int or RandomState instance\n",
            "        Control the shuffling for reproducible behavior.\n",
            "\n",
            "    n_samples : int, None by default\n",
            "        Number of samples to generate. If left to None this is\n",
            "        automatically set to the first dimension of the arrays.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    Sequence of shuffled views of the collections. The original arrays are\n",
            "    not impacted.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    It is possible to mix sparse and dense arrays in the same run::\n",
            "\n",
            "      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\n",
            "      >>> y = np.array([0, 1, 2])\n",
            "\n",
            "      >>> from scipy.sparse import coo_matrix\n",
            "      >>> X_sparse = coo_matrix(X)\n",
            "\n",
            "      >>> from sklearn.utils import shuffle\n",
            "      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n",
            "      >>> X\n",
            "      array([[ 0.,  0.],\n",
            "             [ 2.,  1.],\n",
            "             [ 1.,  0.]])\n",
            "\n",
            "      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
            "      <3x2 sparse matrix of type '<... 'numpy.float64'>'\n",
            "          with 3 stored elements in Compressed Sparse Row format>\n",
            "\n",
            "      >>> X_sparse.toarray()\n",
            "      array([[ 0.,  0.],\n",
            "             [ 2.,  1.],\n",
            "             [ 1.,  0.]])\n",
            "\n",
            "      >>> y\n",
            "      array([2, 1, 0])\n",
            "\n",
            "      >>> shuffle(y, n_samples=2, random_state=0)\n",
            "      array([0, 1])\n",
            "\n",
            "    See also\n",
            "    --------\n",
            "    :func:`sklearn.utils.resample`\n",
            "    \"\"\"\n",
            "    options['replace'] = False\n",
            "    return resample(*arrays, **options)\n",
            "\n",
            "\n",
            "def safe_sqr(X, copy=True):\n",
            "    \"\"\"Element wise squaring of array-likes and sparse matrices.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    X : array like, matrix, sparse matrix\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    X ** 2 : element wise square\n",
            "    \"\"\"\n",
            "    X = safe_asarray(X)\n",
            "    if issparse(X):\n",
            "        if copy:\n",
            "            X = X.copy()\n",
            "        X.data **= 2\n",
            "    else:\n",
            "        if copy:\n",
            "            X = X ** 2\n",
            "        else:\n",
            "            X **= 2\n",
            "    return X\n",
            "\n",
            "\n",
            "def gen_even_slices(n, n_packs):\n",
            "    \"\"\"Generator to create n_packs slices going up to n.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    >>> from sklearn.utils import gen_even_slices\n",
            "    >>> list(gen_even_slices(10, 1))\n",
            "    [slice(0, 10, None)]\n",
            "    >>> list(gen_even_slices(10, 10))                     #doctest: +ELLIPSIS\n",
            "    [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\n",
            "    >>> list(gen_even_slices(10, 5))                      #doctest: +ELLIPSIS\n",
            "    [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\n",
            "    >>> list(gen_even_slices(10, 3))\n",
            "    [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]\n",
            "    \"\"\"\n",
            "    start = 0\n",
            "    for pack_num in range(n_packs):\n",
            "        this_n = n // n_packs\n",
            "        if pack_num < n % n_packs:\n",
            "            this_n += 1\n",
            "        if this_n > 0:\n",
            "            end = start + this_n\n",
            "            yield slice(start, end, None)\n",
            "            start = end\n",
            "\n",
            "\n",
            "def tosequence(x):\n",
            "    \"\"\"Cast iterable x to a Sequence, avoiding a copy if possible.\"\"\"\n",
            "    if isinstance(x, np.ndarray):\n",
            "        return np.asarray(x)\n",
            "    elif isinstance(x, Sequence):\n",
            "        return x\n",
            "    else:\n",
            "        return list(x)\n",
            "\n",
            "\n",
            "class ConvergenceWarning(Warning):\n",
            "    \"Custom warning to capture convergence problems\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer,SFTConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# 1. MODEL CONFIGURATION\n",
        "model_name = \"microsoft/phi-1_5\"\n",
        "\n",
        "# Quantization (4-bit compression)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# LoRA Configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"dense\", \"fc1\", \"fc2\"]\n",
        ")\n",
        "\n",
        "# 2. HELPER FUNCTION TO RELOAD MODEL\n",
        "# We need this to wipe the slate clean between experiments\n",
        "def load_base_model():\n",
        "    print(\"Loading clean Base Model...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        trust_remote_code=True,\n",
        "        dtype=torch.float16\n",
        "    )\n",
        "    model.config.use_cache = False\n",
        "    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
        "\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\" # Fix for fp16 training\n",
        "    return model, tokenizer\n",
        "\n",
        "print(\"Configuration ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQvTaJrD9S39",
        "outputId": "726b65cb-4135-4785-f0c5-e633baebc506"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import bitsandbytes as bnb\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATIONS ---\n",
        "model_name = \"microsoft/phi-1_5\"\n",
        "# Dataset Config\n",
        "hq_dataset_name = \"sahil2801/CodeAlpaca-20k\"\n",
        "lq_dataset_name = \"huggingface-course/codeparrot-ds-train\"\n",
        "# Model/LoRA Config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"dense\", \"fc1\", \"fc2\"]\n",
        ")\n",
        "\n",
        "# --- DATA LOADING ---\n",
        "hq_dataset = load_dataset(hq_dataset_name, split=\"train\").select(range(1000))\n",
        "lq_dataset_raw = load_dataset(lq_dataset_name, split=\"train\", streaming=True).take(5000)\n",
        "# Convert streaming lq_dataset to a list to make it reusable\n",
        "lq_dataset = list(lq_dataset_raw)\n",
        "\n",
        "# --- DATA FORMATTING FUNCTIONS ---\n",
        "def format_hq(sample):\n",
        "    return f\"### Instruction:\\n{sample['instruction']}\\n\\n### Response:\\n{sample['output']}\"\n",
        "def format_lq(sample):\n",
        "    return f\"### Code Snippet:\\n{sample['content']}\"\n",
        "\n",
        "print(\"Setup Complete. Ready for manual training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euhpHkg29lrd",
        "outputId": "646a6d94-263f-4fed-c854-a6e825aaf8dc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup Complete. Ready for manual training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for the DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, formatter_func):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.formatter = formatter_func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        text = self.formatter(sample)\n",
        "        # Tokenize and ensure tensors are returned\n",
        "        return self.tokenizer(text, truncation=True, max_length=512, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "def manual_train(dataset_list, formatting_func, run_name):\n",
        "    print(f\"\\n=== INITIALIZING MANUAL TRAIN: {run_name} ===\")\n",
        "\n",
        "    # 1. Load Model and Tokenizer\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # 2. Apply LoRA Adapters\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # 3. Create DataLoader\n",
        "    train_dataset = TextDataset(dataset_list, tokenizer, formatting_func)\n",
        "    # The collator will handle batching the tokenized outputs\n",
        "    data_collator = lambda data: {'input_ids': torch.cat([f['input_ids'] for f in data]),\n",
        "                                  'attention_mask': torch.cat([f['attention_mask'] for f in data])}\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=2, collate_fn=data_collator)\n",
        "\n",
        "    # 4. Setup Optimizer and GradScaler\n",
        "    optimizer = bnb.optim.PagedAdamW8bit(model.parameters(), lr=2e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler() # THE FIX IS HERE\n",
        "\n",
        "    # 5. The Training Loop\n",
        "    model.train()\n",
        "    max_steps = 150\n",
        "    steps_done = 0\n",
        "    print(f\"--- STARTING TRAINING: {run_name} ---\")\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        if steps_done >= max_steps:\n",
        "            break\n",
        "\n",
        "        # Move batch to GPU\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
        "\n",
        "        # EXPLICITLY USE FLOAT16 with autocast\n",
        "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "            outputs = model(**batch, labels=batch[\"input_ids\"])\n",
        "            loss = outputs.loss\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss.item()}\")\n",
        "\n",
        "        # GradScaler handles the backward pass and scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "        steps_done += 1\n",
        "\n",
        "    # 6. Save and Cleanup\n",
        "    print(f\"--- SAVING ADAPTER: {run_name} ---\")\n",
        "    model.save_pretrained(f\"./final_models/{run_name}\")\n",
        "    print(\"Cleaning up memory...\")\n",
        "    del model, tokenizer, optimizer, scaler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Memory Cleared.\\n\")"
      ],
      "metadata": {
        "id": "VYwsdpqN9ndj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXPERIMENT A: The Textbook (Quality) ---\n",
        "manual_train(hq_dataset, format_hq, \"textbook_adapter\")\n",
        "\n",
        "# --- EXPERIMENT B: The Mess (Quantity) ---\n",
        "manual_train(lq_dataset, format_lq, \"messy_adapter\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66wEX8Z69r8N",
        "outputId": "057ef760-2f49-4696-fed8-db0800751044"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== INITIALIZING MANUAL TRAIN: textbook_adapter ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1443654430.py:42: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler() # THE FIX IS HERE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 14,155,776 || all params: 1,432,426,496 || trainable%: 0.9882\n",
            "--- STARTING TRAINING: textbook_adapter ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/500 [00:00<?, ?it/s]/tmp/ipython-input-1443654430.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 6.908900737762451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 10/500 [00:07<05:57,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10, Loss: 0.2099124789237976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 20/500 [00:14<05:52,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20, Loss: 0.24006858468055725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 30/500 [00:21<05:38,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 30, Loss: 0.29530957341194153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 40/500 [00:29<05:38,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 40, Loss: 0.27605345845222473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 50/500 [00:36<05:29,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 50, Loss: 0.14587172865867615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 60/500 [00:43<05:18,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 60, Loss: 0.17462486028671265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 70/500 [00:51<05:17,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 70, Loss: 0.12328343838453293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 80/500 [00:58<05:06,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 80, Loss: 0.15938618779182434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 90/500 [01:05<05:02,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 90, Loss: 0.06744065135717392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 100/500 [01:13<04:59,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100, Loss: 0.1635114848613739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 110/500 [01:20<04:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 110, Loss: 0.11865776777267456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 120/500 [01:28<04:43,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 120, Loss: 0.1910048872232437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 130/500 [01:35<04:34,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 130, Loss: 0.08683108538389206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 140/500 [01:43<04:30,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 140, Loss: 0.16292370855808258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 150/500 [01:50<04:18,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SAVING ADAPTER: textbook_adapter ---\n",
            "Cleaning up memory...\n",
            "Memory Cleared.\n",
            "\n",
            "\n",
            "=== INITIALIZING MANUAL TRAIN: messy_adapter ===\n",
            "trainable params: 14,155,776 || all params: 1,432,426,496 || trainable%: 0.9882\n",
            "--- STARTING TRAINING: messy_adapter ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 1.217780590057373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 10/2500 [00:07<31:44,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10, Loss: 0.9205238819122314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 20/2500 [00:15<31:55,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20, Loss: 2.611060619354248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 30/2500 [00:22<31:29,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 30, Loss: 1.3235169649124146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 40/2500 [00:30<31:01,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 40, Loss: 1.1919167041778564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 50/2500 [00:37<30:32,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 50, Loss: 1.1526334285736084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 60/2500 [00:45<30:53,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 60, Loss: 1.1740436553955078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 70/2500 [00:53<31:25,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 70, Loss: 1.2876793146133423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 80/2500 [01:00<31:12,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 80, Loss: 1.1805691719055176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 90/2500 [01:08<30:45,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 90, Loss: 1.212113857269287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 100/2500 [01:16<29:46,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100, Loss: 0.9795117378234863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 110/2500 [01:23<29:53,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 110, Loss: 1.4396960735321045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 120/2500 [01:31<29:33,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 120, Loss: 0.8465867638587952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 130/2500 [01:38<29:39,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 130, Loss: 1.2568597793579102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 140/2500 [01:46<29:35,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 140, Loss: 1.2179152965545654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 150/2500 [01:53<29:45,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SAVING ADAPTER: messy_adapter ---\n",
            "Cleaning up memory...\n",
            "Memory Cleared.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# The Prompt\n",
        "instruction = \"Write a Python function that takes a list of numbers and returns the sum of all even numbers.\"\n",
        "prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "def generate(model, name):\n",
        "    print(f\"\\n[{name} GENERATING...]\")\n",
        "    outputs = model.generate(\n",
        "        **inputs, max_new_tokens=120, do_sample=True, temperature=0.2, top_p=0.9\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(result.split(\"### Response:\")[-1])\n",
        "\n",
        "#  TEST 1: TEXTBOOK MODEL\n",
        "model_textbook = PeftModel.from_pretrained(base_model, \"./final_models/textbook_adapter\")\n",
        "generate(model_textbook, \"TEXTBOOK MODEL\")\n",
        "del model_textbook\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# TEST 2: MESSY MODEL\n",
        "model_messy = PeftModel.from_pretrained(base_model, \"./final_models/messy_adapter\")\n",
        "generate(model_messy, \"MESSY MODEL\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0nDNnibCjmu",
        "outputId": "998af7c1-af32-46ac-d1af-2fee7f3eb6b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TEXTBOOK MODEL GENERATING...]\n",
            "\n",
            "def sum_even_numbers(numbers):\n",
            "    total = 0\n",
            "    for num in numbers:\n",
            "        if num % 2 == 0:\n",
            "            total += num\n",
            "    return total\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[MESSY MODEL GENERATING...]\n",
            "\n",
            "def longest_string(strings):\n",
            "    longest = \"\"\n",
            "    for string in strings:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import pandas as pd\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# List of questions for inference\n",
        "inference_questions = [\n",
        "    # Category 1: Simple, \"Textbook\" Problems\n",
        "    \"Write a Python function to find the largest number in a list.\",\n",
        "    \"Create a Python function that checks if a string is a palindrome.\",\n",
        "    \"Write a Python function that calculates the factorial of a number using a loop.\",\n",
        "    \"Generate a Python function that merges two lists and removes duplicates.\",\n",
        "    # Category 2: Logic and Constraints\n",
        "    \"Write a Python function called `fizzbuzz` that prints numbers from 1 to 100. For multiples of 3, print 'Fizz'. For multiples of 5, print 'Buzz'. For multiples of both 3 and 5, print 'FizzBuzz'.\",\n",
        "    \"Create a Python function that takes a dictionary as input and returns a new dictionary with the keys and values swapped.\",\n",
        "    \"Write a Python function `find_primes` that takes an integer `n` and returns a list of all prime numbers up to `n`.\",\n",
        "    \"Generate a Python class `Dog` with a constructor that accepts `name` and `breed`, and includes a method called `bark` that returns the string 'Woof!'.\",\n",
        "    # Category 3: Formatting and Style\n",
        "    \"Write a well-commented Python function to download the content of a webpage given its URL. Include a docstring explaining its usage.\",\n",
        "    # Category 4: The \"Trick\" Question\n",
        "    \"Write a Python function that pretends to connect to a database and returns a fake user record. The function should take no arguments and always return the same dictionary.\",\n",
        "]\n",
        "\n",
        "model_name = \"microsoft/phi-1_5\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "textbook_adapter_path = \"./final_models/textbook_adapter\"\n",
        "messy_adapter_path = \"./final_models/messy_adapter\"\n",
        "\n",
        "# --- 2. LOAD THE BASE MODEL (ONLY ONCE) ---\n",
        "print(\"Loading base model and tokenizer...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ").to('cuda')\n",
        "base_model.eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(\"Base model loaded.\")\n",
        "\n",
        "# --- 3. HELPER FUNCTION FOR GENERATION ---\n",
        "def generate_response(model_adapter_path, prompt_text):\n",
        "    \"\"\"Loads an adapter, generates a response, and cleans up.\"\"\"\n",
        "    model = PeftModel.from_pretrained(base_model, model_adapter_path)\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=256,\n",
        "            do_sample=True,\n",
        "            temperature=0.1,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    cleaned_response = response_text.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return cleaned_response\n",
        "\n",
        "# --- 4. RUN THE EVALUATION LOOP ---\n",
        "results = []\n",
        "print(\"\\nStarting evaluation loop...\")\n",
        "\n",
        "for question in tqdm(inference_questions, desc=\"Evaluating Prompts\"):\n",
        "    prompt = f\"### Instruction:\\n{question}\\n\\n### Response:\\n\"\n",
        "\n",
        "    # Generate for Textbook Model\n",
        "    textbook_response = generate_response(textbook_adapter_path, prompt)\n",
        "\n",
        "    # Generate for Messy Model\n",
        "    messy_response = generate_response(messy_adapter_path, prompt)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"Question\": question,\n",
        "        \"Textbook Model Response\": textbook_response,\n",
        "        \"Messy Model Response\": messy_response\n",
        "    })\n",
        "\n",
        "print(\"Evaluation complete.\")\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"\\n--- INFERENCE RESULTS ---\")\n",
        "display(df_results)\n",
        "\n",
        "# Optional: Save to a CSV file for later\n",
        "df_results.to_csv(\"model_comparison_results.csv\", index=False)\n",
        "print(\"\\nResults saved to model_comparison_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOb5Q9YDEAQD",
        "outputId": "7e44d5e1-f973-462a-b2ea-997b77a7306b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model and tokenizer...\n",
            "Base model loaded.\n",
            "\n",
            "Starting evaluation loop...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Prompts: 100%|██████████| 10/10 [06:57<00:00, 41.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation complete.\n",
            "\n",
            "--- INFERENCE RESULTS ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                            Question  \\\n",
              "0                                                                                                                                      Write a Python function to find the largest number in a list.   \n",
              "1                                                                                                                                  Create a Python function that checks if a string is a palindrome.   \n",
              "2                                                                                                                    Write a Python function that calculates the factorial of a number using a loop.   \n",
              "3                                                                                                                           Generate a Python function that merges two lists and removes duplicates.   \n",
              "4  Write a Python function called `fizzbuzz` that prints numbers from 1 to 100. For multiples of 3, print 'Fizz'. For multiples of 5, print 'Buzz'. For multiples of both 3 and 5, print 'FizzBuzz'.   \n",
              "5                                                                           Create a Python function that takes a dictionary as input and returns a new dictionary with the keys and values swapped.   \n",
              "6                                                                                 Write a Python function `find_primes` that takes an integer `n` and returns a list of all prime numbers up to `n`.   \n",
              "7                                             Generate a Python class `Dog` with a constructor that accepts `name` and `breed`, and includes a method called `bark` that returns the string 'Woof!'.   \n",
              "8                                                               Write a well-commented Python function to download the content of a webpage given its URL. Include a docstring explaining its usage.   \n",
              "9                        Write a Python function that pretends to connect to a database and returns a fake user record. The function should take no arguments and always return the same dictionary.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                       Textbook Model Response  \\\n",
              "0                                                                                                                                                                                                                                                                                                             def find_largest(numbers):\\n    largest = numbers[0]\\n    for number in numbers:\\n        if number > largest:\\n            largest = number\\n    return largest   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                             def is_palindrome(string):\\n    return string == string[::-1]\\n\\nprint(is_palindrome(\"racecar\"))   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                       def factorial(n):\\n    result = 1\\n    for i in range(1, n+1):\\n        result *= i\\n    return result   \n",
              "3                                                                                                                                                                                                     def merge_and_remove_duplicates(list1, list2):\\n    merged_list = list1 + list2\\n    unique_list = list(set(merged_list))\\n    return unique_list\\n\\n# Example usage\\nlist1 = [1, 2, 3, 4, 5]\\nlist2 = [4, 5, 6, 7, 8]\\nprint(merge_and_remove_duplicates(list1, list2))   \n",
              "4                                                                                                                                                                                                           def fizzbuzz(n):\\n    for i in range(1, n+1):\\n        if i % 3 == 0 and i % 5 == 0:\\n            print('FizzBuzz')\\n        elif i % 3 == 0:\\n            print('Fizz')\\n        elif i % 5 == 0:\\n            print('Buzz')\\n        else:\\n            print(i)   \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                       def swap_dict_keys_values(d):\\n    return {v: k for k, v in d.items()}   \n",
              "6                                                                                                                                                                    def find_primes(n):\\n    primes = []\\n    for num in range(2, n+1):\\n        is_prime = True\\n        for i in range(2, int(num**0.5)+1):\\n            if num % i == 0:\\n                is_prime = False\\n                break\\n        if is_prime:\\n            primes.append(num)\\n    return primes   \n",
              "7                                                                                                                                                                                                                                                                                                                    class Dog:\\n    def __init__(self, name, breed):\\n        self.name = name\\n        self.breed = breed\\n    \\n    def bark(self):\\n        return 'Woof!'   \n",
              "8  \"\"\"\\nWrite a well-commented Python function to download the content of a webpage given its URL.\\n\\n\"\"\"\\n\\nimport requests\\n\\ndef download_webpage(url):\\n    \"\"\"\\n    Download the content of a webpage given its URL.\\n\\n    :param url: URL of the webpage to download\\n    :return: HTML content of the webpage\\n    \"\"\"\\n    # Make a request to the URL\\n    response = requests.get(url)\\n\\n    # Return the HTML content of the webpage\\n    return response.content   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                           def fake_user_record():\\n    return {'id': 1, 'name': 'fake_user', 'email': 'fake_email@fake.com'}   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Messy Model Response  \n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 def find_max(lst):\\n    max_num = lst[0]\\n    for i in range(1, len(lst)):\\n        if lst[i] > max_num:\\n            max_num = lst[i]\\n    return max_num\\n\\nprint(find_max([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11,  \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           A palindrome is a word, phrase, number, or other sequence of characters that reads the same backward as forward.\\n\\n``  \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           def max_list(lst):\\n    result = lst[0  \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     def sum_even_numbers(numbers):\\n    \"\"\"\\n    Returns the sum of all the even numbers in a list.\\n    \"\"\"\\n    return sum(filter(lambda x: x % 2 == 0, numbers))\\n\\nprint(sum_even_numbers([1, 2, 3, 4, 5, 6]))\\n# Output: 12\\n```\\n\\n### Exercise 3:\\n\\nWrite a Python function that takes a list of strings and returns a new list with all  \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ```python\\ndef fizzbuzz_list(numbers):\\n    for i in numbers:\\n        if i % 3 == 0 and i % 5 == 0:\\n            print('FizzBuzz')\\n        elif i % 3 == 0:\\n            print('Fizz')\\n        elif i % 5 == 0:\\n            print('  \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ```python\\ndef swap_dicts(lst):\\n    return [{v: k for k, v in d.items()} for d in lst]\\n\\n# Example usage\\nlst = [{'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5, 'f': 6}]\\nprint(swap_dicts(lst))  # Output: [{1: 'a', 2: 'b', 3: 'c'}, {4: 'd', 5: 'e', 6: 'f  \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ```python\\ndef find_primes(n):\\n    primes = []\\n    for num in range(2, n+1):\\n        is_prime = True\\n        for i in range(2, int(num**0.5)+1):\\n            if num %  \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ```  \n",
              "8  ```python\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\ndef download_webpage(url):\\n    \"\"\"\\n    This function downloads the content of a webpage given its URL.\\n    \\n    Parameters:\\n    url (str): The URL of the webpage to download.\\n    \\n    Returns:\\n    str: The content of the webpage.\\n    \"\"\"\\n    response = requests.get(url)\\n    soup = BeautifulSoup(response.content, 'html.parser')\\n    return soup.prettify()\\n```\\n\\n### Exercise 1:\\nWrite a Python function that takes a list of URLs and downloads the content of each webpage using the `download_webpage` function defined above. The function should return a list of the contents of the downloaded webpages.\\n\\n### Solution:\\n```python\\ndef download_webpages(urls):\\n    \"\"\"\\n    This function downloads the content of a list of webpages given their URLs.\\n    \\n    Parameters:\\n    urls (list): A list of URLs of the webpages to download.\\n    \\n    Returns:\\n    list: A list of the contents of the downloaded webpages.  \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ```python\\ndef fake_user():  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a2bcc7-c0e6-41c8-aab0-5c24052b9476\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Textbook Model Response</th>\n",
              "      <th>Messy Model Response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Write a Python function to find the largest number in a list.</td>\n",
              "      <td>def find_largest(numbers):\\n    largest = numbers[0]\\n    for number in numbers:\\n        if number &gt; largest:\\n            largest = number\\n    return largest</td>\n",
              "      <td>def find_max(lst):\\n    max_num = lst[0]\\n    for i in range(1, len(lst)):\\n        if lst[i] &gt; max_num:\\n            max_num = lst[i]\\n    return max_num\\n\\nprint(find_max([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12]))\\nprint(find_max([-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Create a Python function that checks if a string is a palindrome.</td>\n",
              "      <td>def is_palindrome(string):\\n    return string == string[::-1]\\n\\nprint(is_palindrome(\"racecar\"))</td>\n",
              "      <td>A palindrome is a word, phrase, number, or other sequence of characters that reads the same backward as forward.\\n\\n``</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Write a Python function that calculates the factorial of a number using a loop.</td>\n",
              "      <td>def factorial(n):\\n    result = 1\\n    for i in range(1, n+1):\\n        result *= i\\n    return result</td>\n",
              "      <td>def max_list(lst):\\n    result = lst[0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Generate a Python function that merges two lists and removes duplicates.</td>\n",
              "      <td>def merge_and_remove_duplicates(list1, list2):\\n    merged_list = list1 + list2\\n    unique_list = list(set(merged_list))\\n    return unique_list\\n\\n# Example usage\\nlist1 = [1, 2, 3, 4, 5]\\nlist2 = [4, 5, 6, 7, 8]\\nprint(merge_and_remove_duplicates(list1, list2))</td>\n",
              "      <td>def sum_even_numbers(numbers):\\n    \"\"\"\\n    Returns the sum of all the even numbers in a list.\\n    \"\"\"\\n    return sum(filter(lambda x: x % 2 == 0, numbers))\\n\\nprint(sum_even_numbers([1, 2, 3, 4, 5, 6]))\\n# Output: 12\\n```\\n\\n### Exercise 3:\\n\\nWrite a Python function that takes a list of strings and returns a new list with all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a Python function called `fizzbuzz` that prints numbers from 1 to 100. For multiples of 3, print 'Fizz'. For multiples of 5, print 'Buzz'. For multiples of both 3 and 5, print 'FizzBuzz'.</td>\n",
              "      <td>def fizzbuzz(n):\\n    for i in range(1, n+1):\\n        if i % 3 == 0 and i % 5 == 0:\\n            print('FizzBuzz')\\n        elif i % 3 == 0:\\n            print('Fizz')\\n        elif i % 5 == 0:\\n            print('Buzz')\\n        else:\\n            print(i)</td>\n",
              "      <td>```python\\ndef fizzbuzz_list(numbers):\\n    for i in numbers:\\n        if i % 3 == 0 and i % 5 == 0:\\n            print('FizzBuzz')\\n        elif i % 3 == 0:\\n            print('Fizz')\\n        elif i % 5 == 0:\\n            print('</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Create a Python function that takes a dictionary as input and returns a new dictionary with the keys and values swapped.</td>\n",
              "      <td>def swap_dict_keys_values(d):\\n    return {v: k for k, v in d.items()}</td>\n",
              "      <td>```python\\ndef swap_dicts(lst):\\n    return [{v: k for k, v in d.items()} for d in lst]\\n\\n# Example usage\\nlst = [{'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5, 'f': 6}]\\nprint(swap_dicts(lst))  # Output: [{1: 'a', 2: 'b', 3: 'c'}, {4: 'd', 5: 'e', 6: 'f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Write a Python function `find_primes` that takes an integer `n` and returns a list of all prime numbers up to `n`.</td>\n",
              "      <td>def find_primes(n):\\n    primes = []\\n    for num in range(2, n+1):\\n        is_prime = True\\n        for i in range(2, int(num**0.5)+1):\\n            if num % i == 0:\\n                is_prime = False\\n                break\\n        if is_prime:\\n            primes.append(num)\\n    return primes</td>\n",
              "      <td>```python\\ndef find_primes(n):\\n    primes = []\\n    for num in range(2, n+1):\\n        is_prime = True\\n        for i in range(2, int(num**0.5)+1):\\n            if num %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Generate a Python class `Dog` with a constructor that accepts `name` and `breed`, and includes a method called `bark` that returns the string 'Woof!'.</td>\n",
              "      <td>class Dog:\\n    def __init__(self, name, breed):\\n        self.name = name\\n        self.breed = breed\\n    \\n    def bark(self):\\n        return 'Woof!'</td>\n",
              "      <td>```</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Write a well-commented Python function to download the content of a webpage given its URL. Include a docstring explaining its usage.</td>\n",
              "      <td>\"\"\"\\nWrite a well-commented Python function to download the content of a webpage given its URL.\\n\\n\"\"\"\\n\\nimport requests\\n\\ndef download_webpage(url):\\n    \"\"\"\\n    Download the content of a webpage given its URL.\\n\\n    :param url: URL of the webpage to download\\n    :return: HTML content of the webpage\\n    \"\"\"\\n    # Make a request to the URL\\n    response = requests.get(url)\\n\\n    # Return the HTML content of the webpage\\n    return response.content</td>\n",
              "      <td>```python\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\ndef download_webpage(url):\\n    \"\"\"\\n    This function downloads the content of a webpage given its URL.\\n    \\n    Parameters:\\n    url (str): The URL of the webpage to download.\\n    \\n    Returns:\\n    str: The content of the webpage.\\n    \"\"\"\\n    response = requests.get(url)\\n    soup = BeautifulSoup(response.content, 'html.parser')\\n    return soup.prettify()\\n```\\n\\n### Exercise 1:\\nWrite a Python function that takes a list of URLs and downloads the content of each webpage using the `download_webpage` function defined above. The function should return a list of the contents of the downloaded webpages.\\n\\n### Solution:\\n```python\\ndef download_webpages(urls):\\n    \"\"\"\\n    This function downloads the content of a list of webpages given their URLs.\\n    \\n    Parameters:\\n    urls (list): A list of URLs of the webpages to download.\\n    \\n    Returns:\\n    list: A list of the contents of the downloaded webpages.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Write a Python function that pretends to connect to a database and returns a fake user record. The function should take no arguments and always return the same dictionary.</td>\n",
              "      <td>def fake_user_record():\\n    return {'id': 1, 'name': 'fake_user', 'email': 'fake_email@fake.com'}</td>\n",
              "      <td>```python\\ndef fake_user():</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a2bcc7-c0e6-41c8-aab0-5c24052b9476')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02a2bcc7-c0e6-41c8-aab0-5c24052b9476 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02a2bcc7-c0e6-41c8-aab0-5c24052b9476');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1ab10849-26dc-45ec-a200-efbd02d34c2d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ab10849-26dc-45ec-a200-efbd02d34c2d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1ab10849-26dc-45ec-a200-efbd02d34c2d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_48986646-23d8-40f5-8001-5a82d4953262\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_48986646-23d8-40f5-8001-5a82d4953262 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Write a well-commented Python function to download the content of a webpage given its URL. Include a docstring explaining its usage.\",\n          \"Create a Python function that checks if a string is a palindrome.\",\n          \"Create a Python function that takes a dictionary as input and returns a new dictionary with the keys and values swapped.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Textbook Model Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\\"\\\"\\\"\\nWrite a well-commented Python function to download the content of a webpage given its URL.\\n\\n\\\"\\\"\\\"\\n\\nimport requests\\n\\ndef download_webpage(url):\\n    \\\"\\\"\\\"\\n    Download the content of a webpage given its URL.\\n\\n    :param url: URL of the webpage to download\\n    :return: HTML content of the webpage\\n    \\\"\\\"\\\"\\n    # Make a request to the URL\\n    response = requests.get(url)\\n\\n    # Return the HTML content of the webpage\\n    return response.content\",\n          \"def is_palindrome(string):\\n    return string == string[::-1]\\n\\nprint(is_palindrome(\\\"racecar\\\"))\",\n          \"def swap_dict_keys_values(d):\\n    return {v: k for k, v in d.items()}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Messy Model Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"```python\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\ndef download_webpage(url):\\n    \\\"\\\"\\\"\\n    This function downloads the content of a webpage given its URL.\\n    \\n    Parameters:\\n    url (str): The URL of the webpage to download.\\n    \\n    Returns:\\n    str: The content of the webpage.\\n    \\\"\\\"\\\"\\n    response = requests.get(url)\\n    soup = BeautifulSoup(response.content, 'html.parser')\\n    return soup.prettify()\\n```\\n\\n### Exercise 1:\\nWrite a Python function that takes a list of URLs and downloads the content of each webpage using the `download_webpage` function defined above. The function should return a list of the contents of the downloaded webpages.\\n\\n### Solution:\\n```python\\ndef download_webpages(urls):\\n    \\\"\\\"\\\"\\n    This function downloads the content of a list of webpages given their URLs.\\n    \\n    Parameters:\\n    urls (list): A list of URLs of the webpages to download.\\n    \\n    Returns:\\n    list: A list of the contents of the downloaded webpages.\",\n          \"A palindrome is a word, phrase, number, or other sequence of characters that reads the same backward as forward.\\n\\n``\",\n          \"```python\\ndef swap_dicts(lst):\\n    return [{v: k for k, v in d.items()} for d in lst]\\n\\n# Example usage\\nlst = [{'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5, 'f': 6}]\\nprint(swap_dicts(lst))  # Output: [{1: 'a', 2: 'b', 3: 'c'}, {4: 'd', 5: 'e', 6: 'f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/final_models.zip /content/final_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEv_lTvxGRTC",
        "outputId": "944d71ce-b737-45af-920a-7a2aad007816"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/final_models/ (stored 0%)\n",
            "  adding: content/final_models/messy_adapter/ (stored 0%)\n",
            "  adding: content/final_models/messy_adapter/README.md (deflated 65%)\n",
            "  adding: content/final_models/messy_adapter/adapter_config.json (deflated 58%)\n",
            "  adding: content/final_models/messy_adapter/adapter_model.safetensors (deflated 8%)\n",
            "  adding: content/final_models/textbook_adapter/ (stored 0%)\n",
            "  adding: content/final_models/textbook_adapter/README.md (deflated 65%)\n",
            "  adding: content/final_models/textbook_adapter/adapter_config.json (deflated 58%)\n",
            "  adding: content/final_models/textbook_adapter/adapter_model.safetensors (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfNAnyiKGYpI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}